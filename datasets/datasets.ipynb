{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class KorSTSDatasets(Dataset):\n",
    "    def __init__(self, dir_x, dir_y):\n",
    "        self.x = np.load(dir_x, allow_pickle=True)\n",
    "        self.y = np.load(dir_y, allow_pickle=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence1, sentence2 = self.x[idx]\n",
    "        data = torch.IntTensor(sentence1), torch.IntTensor(sentence2)\n",
    "        label = int(float(self.y[idx]))\n",
    "        return data, label\n",
    "\n",
    "dataset = KorSTSDatasets(\"../KorSTS/train_x.npy\", \"../KorSTS/train_y.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((tensor([    2,  7046,  2116, 31389, 19521,  1513,  2062,    18,     3],\n",
      "       dtype=torch.int32), tensor([    2,  7046,  2116, 31389, 19521,  1513,  2062,    18,     3],\n",
      "       dtype=torch.int32)), 5)\n"
     ]
    }
   ],
   "source": [
    "for data in dataset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 19])\n",
      "torch.Size([64, 19])\n",
      "tensor([1.2000, 4.6000, 4.6000, 0.0000, 2.6000, 3.8000, 3.6000, 3.8000, 3.6000,\n",
      "        3.6000, 3.6000, 1.6000, 4.0000, 0.0000, 4.2000, 4.6000, 2.2500, 0.4000,\n",
      "        0.4000, 4.4000, 3.8000, 2.0000, 3.6000, 2.2000, 5.0000, 0.2000, 3.6000,\n",
      "        1.8000, 0.8000, 4.0000, 0.0000, 2.6000, 1.6000, 5.0000, 4.0000, 4.4000,\n",
      "        3.6000, 4.0000, 2.4000, 2.6000, 4.0000, 0.2000, 3.2000, 3.0000, 4.2000,\n",
      "        4.2500, 4.2000, 3.8000, 0.8000, 3.0000, 3.8000, 0.0000, 0.2000, 4.6000,\n",
      "        3.0000, 4.4000, 5.0000, 3.6000, 0.0000, 4.0000, 1.4000, 3.2000, 4.2000,\n",
      "        3.4000])\n"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "\n",
    "\n",
    "def collate_fn_(batch):\n",
    "    # batch = list([((s1, s2), label), ((s1, s2), label), ...])\n",
    "    s1_batches = []\n",
    "    s2_batches = []\n",
    "    labels = []\n",
    "    for b in batch:\n",
    "        data, label = b\n",
    "        s1, s2 = data\n",
    "        s1_batches.append(s1)\n",
    "        s2_batches.append(s2)\n",
    "        labels.append(label)\n",
    "        \n",
    "    s1_batch = pad_sequence(s1_batches, batch_first=True, padding_value=0)\n",
    "    s2_batch = pad_sequence(s2_batches, batch_first=True, padding_value=0)\n",
    "    return s1_batch, s2_batch, torch.Tensor(labels)\n",
    "\n",
    "def bucketed_batch_indices(\n",
    "    sentence_length: List[Tuple[int, int]],\n",
    "    batch_size: int,\n",
    "    max_pad_len: int\n",
    "):\n",
    "    batch_indices_list = []\n",
    "    bucket = defaultdict(list)\n",
    "    for idx, length in enumerate(sentence_length):\n",
    "        s1_len, s2_len = length\n",
    "        x = s1_len//max_pad_len\n",
    "        y = s2_len//max_pad_len\n",
    "        bucket[(x, y)].append(idx)\n",
    "        if len(bucket[(x, y)]) == 64:\n",
    "            batch_indices_list.append(bucket[(x, y)])\n",
    "            bucket[(x, y)] = []\n",
    "    for key in bucket.keys():\n",
    "        batch_indices_list.append(bucket[key])\n",
    "\n",
    "    random.shuffle(batch_indices_list)\n",
    "\n",
    "    return batch_indices_list\n",
    "\n",
    "sentence_length = []\n",
    "for s1, s2 in dataset.x: # [(s1, s2), (s1, s2), ...]\n",
    "    sentence_length.append((len(s1), len(s2)))\n",
    "\n",
    "sampler = bucketed_batch_indices(sentence_length, batch_size=64, max_pad_len=10)\n",
    "train_dataloader = DataLoader(dataset, collate_fn=collate_fn_, batch_sampler=sampler)\n",
    "\n",
    "for data in train_dataloader:\n",
    "    s1, s2, label = data\n",
    "    print(s1.shape)\n",
    "    print(s2.shape)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('boost')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9159c243aea83f1dee5bf2e92f876e1e3460bf528ee8db6da0661d271ff4e3c6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
